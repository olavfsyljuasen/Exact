//--------------------------------------------------------------
// The Lanczos routine computes the Lanczos matrix 
// Diagonalization of the Lanczosmatrix must be done separately
// in the routine LanczosDiag
//
// This file contains the standard serial implementation of Lanczos
//
//
//--------------------------------------------------------------

using namespace std;

#ifdef DEBUG
const bool WTRACE=true;
#else
const bool WTRACE=false;
#endif

#ifdef DEBUG2
const bool TRACE=true;
#else
const bool TRACE=false;
#endif

#include<iostream>
#include<iomanip>


const double TINYNUMBER=1e-15;

#include "unistd.h"
#include "lanczos.h"
#include "rnddef.h"

#include "cuda_runtime.h"
#include <cublas_v2.h>
#include "cuComplex.h"

#include "cuda_global.h"

#include "lanczos_cuda.h" 

#include "lowlevelroutines.h"

#include "global.h"

//Lanczos::Lanczos(MyMatrix& H_in,int M_in){impl = new Lanczos_impl(H_in,M_in);} // initializes Lanczos with random vector
Lanczos::Lanczos(MyMatrix& H_in,int M_in,int basestatenr){impl = new Lanczos_impl(H_in,M_in,basestatenr);} // initializes Lanczos with a basestate 
Lanczos::Lanczos(MyMatrix& H_in,int M_in, vector<MyField>& vec_in){impl = new Lanczos_impl(H_in,M_in,vec_in);}  // initializes Lanczos using the input vector
Lanczos::~Lanczos(){delete impl;} 
void Lanczos::DoLanczos(){impl->DoLanczos();}
MyField* Lanczos::GetInitVector(){return impl->GetInitVector();}
MyField* Lanczos::GetPhi(const int i){return impl->GetPhi(i);}
void Lanczos::DiagonalizeLanczosMatrix(){impl->DiagonalizeLanczosMatrix();}
vector<double>& Lanczos::GetLanczosa(){return impl->GetLanczosa();}
vector<double>& Lanczos::GetLanczosb(){return impl->GetLanczosb();}  // we start numbering b from b0,b1 etc.
vector<double>& Lanczos::GetEigenvalues(){return impl->GetEigenvalues();}
double* Lanczos::GetEigenvector(const int i){return impl->GetEigenvector(i);}
int Lanczos::GetNeigenvalues(){return impl->GetNeigenvalues();}
int Lanczos::GetNLanczosIterations(){return impl->GetNLanczosIterations();}
double Lanczos::GetNormofInitVector(){return impl->GetNormofInitVector();} 
MyField* Lanczos::GetLanczosEigenvectorinStateSpaceBasis(const int n){return impl->GetLanczosEigenvectorinStateSpaceBasis(n);}








/*
Lanczos_impl::Lanczos_impl(MyMatrix& H_in,int M_in):H(H_in),N(H.Ncols()),M(min(N,M_in)),Mstop(M),Niterations(0),phi(NULL),
						    lanczos_a(M),lanczos_b(M-1),LM(0),initnorm(1.),
						    handle(NULL),status(cublasCreate(&handle)),err(cudaSuccess),
						    Rows(H_in.Nrows()),Cols(H_in.Ncols()),Nc(H_in.NStoredCols()),Ntot(Rows*Nc),
						    d_m_val(NULL),d_m_col(NULL),d_phi(NULL),
						    threadsPerBlock(NTHREADSPERBLOCK),
						    blocksPerGrid((Rows + threadsPerBlock - 1)/threadsPerBlock)
  {
    if(WTRACE) cout << "Starting Lanczos, M=" << M << endl;
    phi = new MyField[(M+1)*Cols]; // allocate space for Lanczos vectors

    RandomInitialization(); // randomize before upload. Can also improve by using cuda random numbers

    UploadMatrixToDevice(H,&d_m_val,&d_m_col);
    AllocateSpaceOnDevice((M+1)*Cols,&d_phi);
    UploadToDevice(&phi[0],(M+1)*Cols,&d_phi);

    double initnorm=Normalize(0); // record the normalization of the random vector
    // Choose a random basestate if basestatenr is above limit)
  }
*/

Lanczos_impl::Lanczos_impl(MyMatrix& H_in,int M_in,int basestatenr):H(H_in),N(H.Ncols()),M(min(N,M_in)),Mstop(M),Niterations(0),phi(NULL),
								    lanczos_a(M),lanczos_b(M-1),LM(0),initnorm(1.),
								    handle(NULL),status(cublasCreate(&handle)),err(cudaSuccess),
								    Rows(H_in.Nrows()),Cols(H_in.Ncols()),Nc(H_in.NStoredCols()),Ntot(Rows*Nc),
								    d_m_val(NULL),d_m_col(NULL),d_phi(NULL),
						 		    threadsPerBlock(NTHREADSPERBLOCK),	
						 		    blocksPerGrid((Rows + threadsPerBlock - 1)/threadsPerBlock)
  {
    if(WTRACE) cout << "Starting Lanczos, M=" << M << " with base state " << basestatenr << " Rows:" << Rows << " Cols:" << Cols << " Nc: " << Nc << " Ntot:" << Ntot << endl;
    phi = new MyField[(M+1)*Cols]; // allocate space for Lanczos vectors

    MyField* phi0=&phi[0];

    if(basestatenr >=0 && basestatenr < Cols)
      {
	if(TRACE) cout << "Setting base state: " << basestatenr << endl;
	phi0[basestatenr]=complex<double>(1.,0.); // initialize the vector
	initnorm=1.;
      }
    else
      {     // Choose a random basestate if basestatenr is -1 or >#of states
	RandomInitialization(); // pick a random state
	if(TRACE)
	  {
	    cout << "phi[0]:" << endl;
	    for(int i=0; i<Cols; i++) cout << setprecision(PRECISION) << phi0[i] << endl;
	  }	
      }

    UploadMatrixToDevice(H,&d_m_val,&d_m_col);
    AllocateSpaceOnDevice((M+1)*Cols,&d_phi);
    UploadToDevice(phi0,(M+1)*Cols,&d_phi);

    Normalize(0); // normalize the random vector

    if(TRACE)
      {
	cout << "phi[0]:" << endl;
	InspectDevice(&d_phi,Cols);
      }


    if(TRACE) 
      {
	cout << "the matrix is: " << H << endl;
      }



  }

Lanczos_impl::Lanczos_impl(MyMatrix& H_in,int M_in, vector<MyField>& vec_in):H(H_in),N(H.Ncols()),M(min(N,M_in)),Mstop(M),Niterations(0),phi(NULL),
									     lanczos_a(M),lanczos_b(M-1),LM(0),initnorm(1.),
									     handle(NULL),status(cublasCreate(&handle)),err(cudaSuccess),
									     Rows(H_in.Nrows()),Cols(H_in.Ncols()),Nc(H_in.NStoredCols()),Ntot(Rows*Nc),
									     d_m_val(NULL),d_m_col(NULL),d_phi(NULL),
						  			     threadsPerBlock(NTHREADSPERBLOCK),    
						   			     blocksPerGrid((Rows + threadsPerBlock - 1)/threadsPerBlock)
  {
    if(WTRACE) cout << "Starting Lanczos with initial vector, M=" << M << endl;
    phi = new MyField[(M+1)*Cols]; // allocate space for Lanczos vectors

    MyField* phi0=&phi[0]; // same as phi itself
    for(int i=0; i<N; i++) phi0[i]=vec_in[i]; // initialize the vector

    if(TRACE)
      {
	cout << "phi[0]:" << endl;
	for(int i=0; i<Cols; i++) cout << phi0[i] << " ";
      }


    UploadMatrixToDevice(H,&d_m_val,&d_m_col);
    AllocateSpaceOnDevice((M+1)*Cols,&d_phi);
    UploadToDevice(&phi[0],(M+1)*Cols,&d_phi);


    //    if(TRACE){ cout << "phi[0] after upload" << endl; PrintOutPhi(0);}

    initnorm=Normalize(0); // record the normalization of the init vector, and normalize it
    if(TRACE) cout << "Init norm is: " << initnorm << endl;
    if(abs(initnorm) < TINYNUMBER){Mstop=0; Niterations=0;} // in case the starting vector is the zero vector
  }


Lanczos_impl::~Lanczos_impl()
{
  if(WTRACE) cout << "Destroying class Lanczos" << endl;
  cublasDestroy(handle);
  delete[] phi;
  delete LM;
}

void Lanczos_impl::PrintOutPhi(const int m)
{
	DownloadFromDevice(&d_phi,(M+1)*Cols,phi);
	MyField* phim=&phi[m*Cols];		
	cout << "phi_" << m << " =" << endl;
	for(int i=0; i<Cols; i++){cout << phim[i] << " " << endl;} 
}

/*
void Lanczos_impl::PrintOutMatrix()
{
	DownloadMatrixFromDevice();
	cout << H << endl;
}
*/

void Lanczos_impl::DoLanczos()
{
  if(TRACE) cout << "Starting DoLanczos (lanczos_cuda.cu)" << endl;
  int m=0;
  bool continueiteration=true;
  while(continueiteration && m<Mstop){
    if(TRACE) cout << "Doing Lanczos step m:" << m << " M: " << M << endl;
    continueiteration=LanczosIteration(m++);
  } 
  Niterations=m; // gives the number of lanczos vectors
  if(TRACE){
    cout << "There are in all " << Niterations << " orthogonal Lanczos vectors" << endl;
    if(Niterations >0)
      {
	for(int i=0; i<Niterations-1; i++){
	  cout << "a[" << i << "]=" << lanczos_a[i] << " b[" << i << "]="<< lanczos_b[i] << endl;}
	cout << "a[" << Niterations-1 << "]=" << lanczos_a[Niterations-1] << endl;
      }
  }

 DownloadFromDevice(&d_phi,(M+1)*Cols,phi);
 FreeMatrixOnDevice(&d_m_val,&d_m_col);
 FreeMemoryOnDevice(&d_phi);
}


//MyField* Lanczos_impl::GetInitVector(){return &phi[0];}

double Lanczos_impl::Normalize(int i)
{
  if(WTRACE) cout << "in Lanczos_impl::Normalize" << endl;
  double norm=0.;
  cublasDznrm2(handle,Cols,&d_phi[i*Cols],1,&norm);
  double factor=1./norm;
  cublasZdscal(handle,Cols,&factor,&d_phi[i*Cols],1);

  return norm;
}

void Lanczos_impl::RandomInitialization()
  {
  if(WTRACE) cout << "In RandomInitialization" << endl;
    MyField* phi0=&phi[0];
    for(int i=0; i<Cols; i++)
      {
	double r_real=2.*RAN.Get()-1.;
	double r_imag=2.*RAN.Get()-1.;

	MyField r=MyField(r_real,r_imag); // random start

	phi0[i]=r;
      }
  }

void Lanczos_impl::Reorthogonalize(const int m)
  {
    if(TRACE) cout << "Starting Reorthogonalize with m=" << m << endl; 
    cuda_cmplx q=cmplx_0;
    cuda_cmplx q0=cmplx_0;
    cuda_cmplx negq1=cmplx_0;

    if(TRACE) cout << "q:" << q << endl; 

    for(int i=0; i<m; i++)
      {
	cublasZdotc(handle,Cols,&d_phi[m*Cols],1,&d_phi[i*Cols],1,&q); // q=<phi_m|phi_i>
	q0=cuCdiv(cmplx_1,cuCsub(cmplx_1,cuCmul(q,q)));
	negq1=cuCmul(cuCsub(cmplx_0,q0),q);
	if(TRACE) 
	  {
	    cout << "m: " << m << endl;
	    cout << "q  =" << setprecision(PRECISION) << q << endl; 
	    cout << "q0 =" << setprecision(PRECISION) << q0 << endl;
	    cout << "-q1=" << setprecision(PRECISION) << negq1 << endl;
	  }

	cublasZscal(handle,Cols,&q0,&d_phi[m*Cols],1); // phi_m -> q0*|phi_m>
	cublasZaxpy(handle,Cols,&negq1, &d_phi[i*Cols],1,&d_phi[m*Cols],1); // phi_m = phi_m -q1*phi_i;
      }
    if(TRACE) cout << "Done Reorthogonalize" << endl; 
  }

bool Lanczos_impl::LanczosIteration(const int m)
  {
    if(WTRACE)  cout << "Starting Lanczos iteration " << m << endl;
    Niterations++;

    if(m==0)
      { // first element
	/* v1=H*v0
	vector<MyField>& v0=*(phi[0]); //already normalized
	vector<MyField>& v1=*(phi[1]);
	H.TimesVector(v1,v0);
	*/
	if(TRACE) cout << "Launching cuda_mat_vec_multiply_cmplx with " << blocksPerGrid << " blocks and " << threadsPerBlock  << " threads per block" << endl; 
	cuda_mat_vec_multiply_cmplx<<<blocksPerGrid,threadsPerBlock>>>(Rows,Nc,d_m_col ,d_m_val, &d_phi[0], &d_phi[1*Cols]); // v1=H*v0 
   	err = cudaGetLastError();						     
	if(TRACE) cout << "end of cuda_mat_vec_multiply_cmplx, last error" << err << endl; 

	if(TRACE)
	  {
	    cout << "d_phi1: "<< endl;
	    cuda_cmplx* temp=&d_phi[1*Cols];
	    InspectDevice(&temp,Cols);
	  }

	/*
	lanczos_a[0]=ScalarProduct(v0,v1).real();
	*/
	cuda_cmplx a=cmplx_0;
	if(TRACE) cout << "Launching cublasZdotc" << endl; 
	cublasZdotc(handle,Cols,&d_phi[0],1,&d_phi[1*Cols],1,&a);
	lanczos_a[0]= cuCreal(a); // a=Re(<v0|v1>)
	if(TRACE) cout << "lanczos_a[0]=" << lanczos_a[0] << endl;


	if(M>1) // if not the last element
	  {
	    /*
	    ConstructGamma1(v1,v0,lanczos_a[0]);
	    */
	    a=make_cuDoubleComplex(-lanczos_a[0],0.);
	    if(TRACE) cout << "a=(" << cuCreal(a) << "," << cuCimag(a) << ")" << endl; 
	    if(TRACE) cout << "Launching cublasZaxpy" << endl;	
	    cublasZaxpy(handle,Cols,&a, &d_phi[0],1,&d_phi[1*Cols],1); // v1=v1-a*v0

	    if(REORTHOGONALIZE) Reorthogonalize(1);
	    lanczos_b[0]=Normalize(1);
	    if(TRACE) cout << "lanczos_b[0]=" << lanczos_b[0] << endl;
	  }
      }
    else
      {
	if(TRACE) cout << "Launching cuda_mat_vec_multiply_cmplx with " << blocksPerGrid << " blocks and " << threadsPerBlock  << " threads per block" << endl; 
	cuda_mat_vec_multiply_cmplx<<<blocksPerGrid,threadsPerBlock>>>(Rows,Nc,d_m_col ,d_m_val, &d_phi[m*Cols], &d_phi[(m+1)*Cols]); // phi_mp1=H*phi_m 
    	err = cudaGetLastError();							        	      
	if(TRACE) cout << "end of cuda_mat_vec_multiply_cmplx, last error=" << err << endl; 

	cuda_cmplx am=cmplx_0;
	if(TRACE) cout << "Launching cublasZdotc" << endl; 
	cublasZdotc(handle,Cols,&d_phi[m*Cols],1,&d_phi[(m+1)*Cols],1,&am);
	if(TRACE) cout << "Last Cuda error: " << cudaGetLastError() << endl;
	lanczos_a[m]= cuCreal(am); // am=Re(<phi_m|phi_{m+1}>)
	if(TRACE) cout << "lanczos_a[" << m << "]=" << lanczos_a[m] << endl;
	if(m < M-1) // not last element
	  {
	    // computes v_mp1 -> v_mp1-am*v_m-bmm1*v_mm1
	    
	    cuda_cmplx negam=make_cuDoubleComplex(-lanczos_a[m],0.);
	    if(TRACE) cout << "Launching cublasZaxpy" << endl;	
	    cublasZaxpy(handle,Cols,&negam, &d_phi[m*Cols],1,&d_phi[(m+1)*Cols],1); // phi_mp1=phi_mp1-am*phi_m
	    if(TRACE) cout << "Last Cuda error: " << cudaGetLastError() << endl;

	    cuda_cmplx negbmm1=make_cuDoubleComplex(-lanczos_b[m-1],0.);
	    if(TRACE) cout << "Launching cublasZaxpy" << endl;	
	    cublasZaxpy(handle,Cols,&negbmm1, &d_phi[(m-1)*Cols],1,&d_phi[(m+1)*Cols],1); // phi_mp1=phi_mp1 - bmm1*phi_mm1;
	    if(TRACE) cout << "Last Cuda error: " << cudaGetLastError() << endl;

	    if(REORTHOGONALIZE) Reorthogonalize(m+1);
	    lanczos_b[m]=Normalize(m+1);
	    if(TRACE) cout << "lanczos_b[" << m << "]=" << lanczos_b[m] << endl;	
	  }
      }

    
    if(TRACE){ 
      cout << "Lanczos vector after iteration #: " << m << endl;
      cuda_cmplx* d_ptr=&d_phi[m*Cols];
      InspectDevice(&d_ptr,Cols);

      cout << "a[" << m << "]=" << setprecision(PRECISION) << lanczos_a[m];
      if(m<M-1) cout << " b[" << m << "]=" << setprecision(PRECISION) << lanczos_b[m];
      cout << endl;
    }

    

    if(m<M-1 && abs(lanczos_b[m])<=TINYNUMBER){return false;} // stop the Lanczos procedure; 
    return true;
  }

void Lanczos_impl::DiagonalizeLanczosMatrix()
{
  if(Niterations==0) return;
  delete LM;
  LM = new LanczosMatrix(Niterations,lanczos_a,lanczos_b);
  LM->Diagonalize();
}

MyField* Lanczos_impl::GetLanczosEigenvectorinStateSpaceBasis(const int n)
{
  MyField* phiM=&phi[M*Cols]; // the last one is used as storage
  double* nu=LM->Eigenvector(n);

  for(int i=0; i<N; i++){ phiM[i]=0;} // initialize to zero.
  for(int p=0; p<Niterations; p++)
    {
      MyField* phip=&phi[p*Cols];
      AddToVector(&N,phiM,phip,&nu[p]);	 
    }
  return phiM;
}

/*
int Lanczos_impl::UploadMatrixToDevice()
{
  if(TRACE) cout << "In UploadMatrixToDevice" << endl;	
  cuda_cmplx* m_val=reinterpret_cast<cuda_cmplx*>(H.GetValStartPtr());
  int*     m_col=H.GetColStartPtr();

  if (cudaMalloc((void **)&d_m_val, Ntot*sizeof(m_val[0])) != cudaSuccess)
    {
      fprintf(stderr, "!!!! device memory allocatioNerror (allocate d_m_val)\n");
      return EXIT_FAILURE;
    }

  if (cudaMalloc((void **)&d_m_col, Ntot*sizeof(m_col[0])) != cudaSuccess)
    {
      fprintf(stderr, "!!!! device memory allocatioNerror (allocate d_m_col)\n");
      return EXIT_FAILURE;
    }

  // upload the matrix to the GPU
  err = cudaMemcpy(d_m_val, m_val, Ntot*sizeof(m_val[0]), cudaMemcpyHostToDevice);

  if(err != cudaSuccess )
    {
      fprintf(stderr, "Failed to copy vector m_val from host to device (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }

  err = cudaMemcpy(d_m_col, m_col, Ntot*sizeof(m_col[0]), cudaMemcpyHostToDevice);

  if(err != cudaSuccess )
    {
      fprintf(stderr, "Failed to copy vector m_col from host to device (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }
  return cudaSuccess;
}

int Lanczos_impl::DownloadMatrixFromDevice()
{
  if(TRACE) cout << "In DownloadMatrixFromDevice" << endl;	
  cuda_cmplx* m_val=reinterpret_cast<cuda_cmplx*>(H.GetValStartPtr());
  int*     m_col=H.GetColStartPtr();


  // download the matrix from the GPU
  err = cudaMemcpy(m_val,d_m_val, Ntot*sizeof(m_val[0]), cudaMemcpyDeviceToHost);

  if(err != cudaSuccess )
    {
      fprintf(stderr, "Failed to copy vector m_val from device to host (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }

  err = cudaMemcpy(m_col, d_m_col, Ntot*sizeof(m_col[0]), cudaMemcpyDeviceToHost);

  if(err != cudaSuccess )
    {
      fprintf(stderr, "Failed to copy vector m_col from device to host (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }
  return cudaSuccess;
}
*/


/*
int Lanczos_impl::UploadLanczosVectorsToDevice()
{
  if(TRACE) cout << "In UploadLanczosVectorsToDevice" << endl;	
  if(TRACE) cout << "sizeof(cuda_cmplx)=" << sizeof(cuda_cmplx) << " sizeof(MyField)="  << sizeof(MyField) << endl;

  // allocate space on the GPU
  if (cudaMalloc((void **)&d_phi, (M+1)*Cols*sizeof(cuda_cmplx)) != cudaSuccess)
    {
      fprintf(stderr, "!!!! device memory allocatioNerror (allocate d_phi)\n");
      return EXIT_FAILURE;
    }
      
      // upload the input vector to the GPU
  err = cudaMemcpy(d_phi, phi, (M+1)*Cols*sizeof(cuda_cmplx), cudaMemcpyHostToDevice);
  
  if(err != cudaSuccess )
	{
	  fprintf(stderr, "Failed to copy vector phi from host to device (error code %s)!\n", cudaGetErrorString(err));
	  exit(EXIT_FAILURE);
	}

  if(TRACE) cout << "done with UploadLanczosVectorsToDevice" << endl;	
  return cudaSuccess;
}
*/

 /*
int Lanczos_impl::DownloadLanczosVectorsFromDevice()
{
  if(TRACE) cout << "In DownloadLanczosVectorsFromDevice" << endl;	

  // download the vector to the GPU

  cuda_cmplx* temp= reinterpret_cast<cuda_cmplx*>(phi);

  err = cudaMemcpy(temp, d_phi, (M+1)*Cols*sizeof(cuda_cmplx), cudaMemcpyDeviceToHost);
  
  if(err != cudaSuccess )
    {
      fprintf(stderr, "Failed to copy vector phi from device to host (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }  
  if(TRACE) cout << "done with DownloadLanczosVectorsFromDevice" << endl;	
  return cudaSuccess;
}
 */




  /*
int Lanczos_impl::FreeMemoryOnDevice()
{
  if(TRACE) cout << "In FreeMemoryOnDevice" << endl;	
  //free up the memory on the GPU

  err = cudaFree(d_m_col);
    
  if (err != cudaSuccess)
    {
      fprintf(stderr, "Failed to free device vector d_m_col (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }

  err = cudaFree(d_m_val);
    
  if (err != cudaSuccess)
    {
      fprintf(stderr, "Failed to free device vector d_m_val (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }
  

  err = cudaFree(d_phi);
      
  if (err != cudaSuccess)
    {
      fprintf(stderr, "Failed to free device vector d_phi (error code %s)!\n", cudaGetErrorString(err));
      exit(EXIT_FAILURE);
    }


  if(TRACE) cout << "Done with FreeMemoryOnDevice" << endl;	
  return cudaSuccess;
}*/



